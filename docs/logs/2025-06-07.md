# 📆 2025-06-07 学习计划

### 🎥 视频课程（目标：4个）

- [x] **selenium+WebDriver环境搭建(windows)**<br/>
通过webdriver控制浏览器，selenium来操作浏览器
- 1、安装python版本（python3.7及以上版本）
- 2、安装selenium：pip install selenium
- 3、查看需要测试的浏览器版本（可更新至最新）：去搜索下载对应浏览器的WebDriver
- 4、将下载下来的WebDriver压缩包解压放到python的安装根目录下（省去了配置环境变量）
- 5、禁止浏览器静默更新导致与WebDriver版本不匹配：计算机管理界面--服务--找到对应浏览器的更<br/>
新服务；如果使用的是Windows系统的chromdriver，那么可以安装一个名叫safedriver的python库：<br/>
pip install safedriver，可以在启动的时候自动去检查本地的Chrome浏览器版本与你的chromdriver的<br/>
版本是否相匹配，如果两者不匹配，会自动在后台帮你下载与你浏览器相匹配的webdriver对象，保存<br/>
到python的安装根路径下。<br/>
pip过程中如果出现read timeout error,请在pip时添加国内镜像源，或者加上--defaults-timeout=1000
- 6、校验环境是否部署成功：编码以下基本内容
    ```python
  #创建一个浏览器对象（实际是创建了一个浏览器驱动，启动了一个webdriver.exe文件），会去调用本地的浏览器
  #代码通过webdriver启动了浏览器之后，此时的webdriver就类似于启动了一个proxy，代码下发的所有内容都通过
  #webdriver把指令下发给了浏览器，也就是先把指令给了webdriver，再由webdriver把指令下发给浏览器，
  #同样浏览器返回的内容也是先返回给webdriver，再从webdriver返回给到我们
    from selenium import webdriver
    driver = webdriver.chrome() 
    ```
---

- [x] **python+WebDriver实现webUI的自动化**<br/>
- 1、在运行中可能会遇到一启动打开浏览器之后会快速自动关闭浏览器，可能是selenium版本过高导致：<br/>
    - 查看当前版本：pip show selenium      
    - 卸载selenium：pip uninstall selenium
    - 降低到较老版本（例如4.1.1）：pip install selenium==4.1.1





---


### 💻 面试题刷题（牛客网）
# 什么是 IO 操作？‌


IO 操作是指程序与外部设备或资源进行数据输入（Input）和输出（Output）的过程。常见的 IO 操作包括读取磁盘文件、写入日志、访问数据库、发送网络请求等。这些操作通常相对耗时，容易成为系统性能瓶颈，因此在性能测试中是重点关注对象。

### **精简要点**
- **类型**：磁盘 IO（如文件读写）、网络 IO（如 HTTP 请求）、数据库 IO（如查询）。
- **特点**：通常较慢，涉及硬件交互，可能导致性能瓶颈。
  - 耗时高：相较于 CPU 运算，IO 操作速度慢，容易阻塞主线程。
  - 非实时性：特别是网络 IO，受外部环境影响大。
  - 并发需求：常用异步/多线程方式优化性能。

### 在测试中的关注点

| 关注点    | 描述                                                    |
| ------ |-------------------------------------------------------|
| 性能测试   | 网络 IO 和数据库 IO 是否成为瓶颈<br/>  评估I/O操作的效率，检查系统在高负载情况下的表现。 |
| 安全性测试   | 验证输入数据的有效性，防止注入攻击和数据泄露。                                   |
| 稳定性测试  | 异常网络是否会导致系统崩溃                                         |
| 边界测试   | 读取空文件、大文件、断网场景                                        |
| 超时重试机制 | 是否有合理的超时设置和重试逻辑                                       |
| 缓存机制   | 是否能减少重复的 IO 操作，提升性能                                   |



  ```bash
  # 测试磁盘读写性能
  dd if=/dev/zero of=testfile bs=1M count=100
  ```

### **面试回答示例**
> **面试官**：什么是 IO 操作？
>
> **回答**：IO 操作是计算机与外部设备或存储介质交换数据的过程，如文件读写、网络请求、数据库查询。特点是速度慢，易成瓶颈。理解I/O操作对于软件测试人员来说至关重要，因为它直接影响到程序的功能、性能和安全性。在测试中，我用 `dd` 测试磁盘 IO 性能，用 JMeter 模拟网络 IO，发现瓶颈后优化响应时间 20%。



---

# linux 查找当前目录下所有后缀为 .py文件？‌

1、使用 `find` 命令查找当前目录下所有 `.py` 文件（包括其子目录）：
```bash
find . -type f -name "*.py"
```

2、使用 `find` 命令只查找当前目录下的 `.py` 文件（不包括子目录）：
```bash
find . -maxdepth 1 -type f -name "*.py"
```
-maxdepth 1：限制查找的深度为1，即只查找当前目录下的文件，不进入子目录。

### **精简要点**
- **命令解析**：
  - `.`：表示当前目录。
  - `-type f`：表示仅查找文件类型。
  - `-name "*.py"`：匹配后缀为 `.py` 的文件。
- **测试相关**：常用于查找测试脚本或分析项目文件。
  - 示例：统计 Python 脚本数量：
    ```bash
    find . -type f -name "*.py" | wc -l
    ```


### **面试回答示例**
> **面试官**：Linux 如何查找当前目录下所有后缀为 .py 的文件？
>
> **回答**：用 `find . -type f -name "*.py"` 查找当前目录下所有 `.py` 文件。在测试中，我用此命令定位自动化脚本，结合 `wc -l` 统计数量，确保覆盖所有测试用例。



---


# GET 的长度限制了解么？‌

GET 请求的长度限制主要由浏览器和服务器决定，通常为 **2048 到 8192 字符**，具体取决于实现。URL（包括路径和查询参数）过长可能被截断或拒绝。

### **精简要点**
- **限制来源**：
  - 浏览器：如 Chrome (~8KB)、IE (~2KB)。
  - 服务器：如 Nginx (~8KB)、Apache (~4KB)。
  - HTTP 协议本身无明确限制，但实际受限于实现。
- **影响**：查询参数过多或过长可能导致 414 错误（URI Too Long）。
- **测试相关**：验证超长 GET 请求的处理，检查截断或错误响应。
  ```bash
  curl "http://example.com/?data=$(python -c 'print("a"*5000)')"
  ```

### **面试回答示例**
> **面试官**：GET 的长度限制了解么？
>
> **回答1**：GET 请求长度通常受浏览器和服务器限制，约为 2KB 到 8KB，如 Chrome 支持 ~8KB，IE ~2KB。超长 URL 可能被截断或返回 414 错误。在测试中，我用 `curl` 构造超长 GET 请求，验证服务器响应，发现 Nginx 默认 8KB 限制，调整配置后解决。需测试边界和错误处理。

> **回答2**：虽然 HTTP 协议本身没有对 GET 请求的 URL 长度做明确限制，但不同浏览器和服务器对 URL 长度是有限制的。通常建议 GET 请求的 URL 长度不要超过 2000 个字符，以避免被截断或拒绝处理。


---


# Python中，dict的底层结构，tuple和list的底层结构的区别？‌

### 对比表

| 特性           | `dict`         | `list`     | `tuple`       |
| ------------ | -------------- | ---------- | ------------- |
| 底层结构         | 哈希表            | 动态数组       | 静态数组          |
| 可变性          | 可变             | 可变         | 不可变           |
| 是否可作为 dict 键 | 否（除非被 hash）    | 否          | 是（若元素也可 hash） |
| 元素访问效率       | O(1) 通过 key 查找 | O(1) 按索引访问 | O(1) 按索引访问    |
| 内存占用         | 高（存储键值对 + 哈希）  | 中（连续内存）    | 低（不可变更稳定）     |


 ### 📌 1. dict 的底层结构：哈希表
  - 使用 哈希函数 将键（key）映射为哈希值，再定位到对应的数组下标。
  - 每个元素是一个 key-value 对。
  - 使用 开放寻址法（open addressing） 来处理哈希冲突。
  - 支持快速的插入、删除和查找操作（平均时间复杂度 O(1)）。

**特性**
  - 键必须是 可哈希对象（如 int、str、tuple），即实现了 __hash__() 方法。
  - 顺序在 Python 3.7+ 开始变为 有序（按插入顺序）。

 ### 📌 2. list 的底层结构：动态数组
  - 底层是一个 变长的数组（连续内存块）。
  - 允许快速的 按索引访问（O(1)）。
  - 支持动态扩容（例如：2 倍扩容策略），扩容时可能导致拷贝，代价较高。

### 📌 3. tuple 的底层结构：静态数组
  - 和 list 类似，也是用数组结构存储数据。
  - 不可变性：定义后内容不可修改，结构和引用都不能改变。
  - 因此，tuple 的性能略优于 list，且可以作为字典的键。

---

### 描述
- **dict 底层结构**：基于**哈希表**（开放寻址法），键通过哈希函数映射到数组索引，处理冲突用线性探测。时间复杂度平均 O(1)（查找、插入、删除）。
- **tuple 底层结构**：固定大小的**连续数组**，存储元素引用，长度不可变，内存分配一次性完成。
- **list 底层结构**：动态大小的**连续数组**（动态扩容），存储元素引用，支持追加、删除，扩容时重新分配内存。
- **tuple vs list 区别**：
  - **可变性**：tuple 不可变，list 可变。
  - **内存**：tuple 固定，内存开销小；list 动态，预留空间，内存开销大。
  - **性能**：tuple 访问略快，list 因扩容插入/删除稍慢。

### **精简要点**
- **dict**：哈希表，O(1) 操作，键需可哈希。
- **tuple**：固定数组，不可变，高效存储。
- **list**：动态数组，可变，扩容灵活。
- **测试相关**：验证 dict 查找性能、tuple/list 内存使用和操作效率。
  ```python
  import sys
  t = (1, 2, 3)
  l = [1, 2, 3]
  print(sys.getsizeof(t), sys.getsizeof(l))  # tuple 内存 < list
  ```

### **面试回答示例**
> **面试官**：Python 中 dict 的底层结构，tuple 和 list 的底层结构区别？
>
> **回答1**：**dict** 用哈希表实现，键映射到数组索引，平均 O(1)。**tuple** 是固定数组，不可变，内存小，访问快；**list** 是动态数组，可变，支持扩容，内存开销大。在测试中，我用 `sys.getsizeof` 比较 tuple 和 list 内存，发现 tuple 更省空间，用 `timeit` 测试 dict 查找性能，优化了 API 响应时间。需关注 dict 冲突和 list 扩容性能。

> **回答2**：Python 中的 dict 是基于 哈希表（Hash Table） 实现的，而 list 和 tuple 都是基于 数组结构 实现的，但两者的差别在于可变性。list 是可变数组，支持动态增删元素，而 tuple 是不可变数组，定义后元素不能被修改。

---


# 网页卡顿的原因是什么？‌

网页卡顿的原因包括：**前端渲染复杂**（如过多 DOM 操作、CSS 动画）、**JavaScript 执行阻塞**（如复杂计算）、**网络延迟**（如资源加载慢）、**服务器响应慢**、**浏览器兼容性问题**、**设备性能不足**。

### **以下几个方面问题**
- **前端性能问题**：DOM 操作频繁、CSS 重排重绘、JS 阻塞。
  - JavaScript 执行阻塞：大量或复杂的脚本逻辑（如死循环、大量 DOM 操作）。
  - DOM 渲染复杂：页面结构庞大或频繁重排（Reflow）和重绘（Repaint）。
  - 动画过多/未优化：CSS 动画未使用 GPU 加速，影响主线程。
  - 事件监听过多：监听器绑定过多或未解绑，导致响应延迟。
- **资源加载问题**：
  - 图片、视频、JS、CSS 等资源过大或过多。
  - 第三方库加载慢或不可达（如 CDN 异常）。
  - 缓存未命中，所有资源每次都重新下载。
- **网络问题**：大文件加载、弱网、API 响应慢。
  - 网络带宽不足，或用户使用的是弱网环境。
  - DNS 解析慢或不稳定。
  - 请求数量过多或串行发送，未使用并发/懒加载/合并等优化方式。
- **后端问题**：服务器处理延迟、数据库查询慢。
  - 接口响应时间长，阻塞前端渲染。
  - 后端服务压力大或异常，返回超时或数据异常。
  - 使用同步接口阻塞渲染流程。
- **浏览器/硬件限制**：低端设备 CPU/内存不足。
  - 浏览器版本太旧，未优化渲染管线。
  - 用户设备内存/CPU 使用率过高。
  - 多标签页同时打开，占用系统资源。


- **测试相关**：用 Lighthouse 分析渲染性能，Chrome DevTools 监控 JS 执行。

  - 使用浏览器 开发者工具（如 Chrome DevTools）查看：
    - 网络请求时间
    - 页面加载时间（Load、DOMContentLoaded）
    - 性能面板中的帧率、JS 执行时间
  - 使用 Lighthouse 分析页面性能
  - 模拟弱网、CPU 限制等场景测试页面反应
  - 对比线上与本地环境，看是否为环境或资源问题

  ```bash
  lighthouse https://example.com --output=html
  ```


### **面试回答示例**
> **面试官**：网页卡顿的原因是什么？
>
> **回答1**：网页卡顿可能由前端复杂渲染、JS 阻塞、网络延迟、服务器响应慢、浏览器兼容性或设备性能不足引起。在测试中，我用 Lighthouse 发现 DOM 操作过多，用 DevTools 优化 JS 执行，页面加载时间缩短 30%。需测试渲染、网络和设备场景。

> **回答2**：网页卡顿可能由前端性能瓶颈、网络延迟、后端响应慢、资源加载问题或客户端硬件限制等多种原因引起。在测试时，我们通常会从浏览器性能、网络请求、脚本执行、DOM 操作等方面进行排查。

---


# Python中，什么是协程？‌

### **1. 什么是协程？**
协程（Coroutine）是 Python 中一种**轻量级的用户态并发机制**，用于实现异步编程。它允许在单线程内通过协作式调度执行多个任务，特别适合 **I/O 密集型任务**（如网络请求、文件读写）。与线程或进程不同，协程由程序显式控制任务切换，非抢占式，避免了操作系统级别的上下文切换开销。

协程是一种可以在执行过程中被挂起并在稍后恢复的函数。它允许在同一线程中高效的管理和执行多个任务，从而实现非阻塞的异步编程。

### **2. 核心特点**
- **单线程并发**：在同一线程内，通过事件循环（Event Loop）调度多个协程，模拟并发效果。
- **协作式调度**：协程在 `await` 处主动让出控制权，等待 I/O 操作完成后再恢复执行。
- **轻量级**：相比线程/进程，协程内存开销小，,能够在同一线程中高效地管理多个任务,支持高并发（如上万任务）。
- **异步语法**：通过 `async def` 定义协程函数，`await` 暂停执行，`asyncio` 提供运行支持。

### **3. 协程 vs 其他并发模型**
| **特性**           | **协程**                              | **线程**                              | **进程**                              |
|--------------------|---------------------------------------|---------------------------------------|---------------------------------------|
| **调度方式**       | 用户态，协作式                        | 内核态，抢占式                        | 内核态，抢占式                        |
| **开销**           | 轻量（KB 级）                        | 中等（MB 级栈）                      | 较重（独立地址空间）                  |
| **并发规模**       | 高（万级）                           | 中（百级）                           | 低（十级）                           |
| **适用场景**       | I/O 密集型（如网络、文件）            | CPU 或 I/O 密集型                    | CPU 密集型或隔离任务                  |
| **Python 实现**    | `asyncio`、`async/await`             | `threading`                          | `multiprocessing`                    |

---

## **二、协程的原理**

### **1. 协程的起源**
- 协程概念源于生成器（Generator），Python 早期通过 `yield` 实现简单的协程功能。
- Python 3.5+ 引入 `async/await` 语法（PEP 492），基于事件循环和协程对象，标准化异步编程。

### **2. 工作机制**
协程通过以下组件协同工作：
- **协程函数**：用 `async def` 定义，返回协程对象（Coroutine Object）。
  ```python
  async def my_coro():
      return "Hello"
  ```
- **事件循环**：驱动协程执行，管理任务调度，常见实现是 `asyncio.get_event_loop()`。
- **await 表达式**：暂停协程执行，等待异步操作（如 I/O）完成，交出控制权。
- **任务（Task）**：封装协程的执行单元，通过 `asyncio.create_task()` 创建。
- **Future**：表示尚未完成的操作，协程通过 `await` 等待 Future 结果。

### **3. 执行流程**
1. 定义协程函数，用 `async def`。
2. 创建协程对象，调用协程函数（如 `my_coro()`）。
3. 将协程包装为任务，加入事件循环（如 `loop.create_task()`）。
4. 事件循环调度任务，遇到 `await` 暂停，切换到其他任务。
5. I/O 操作完成后，恢复协程执行，直至完成。

### **4. 事件循环的作用**
- 事件循环是协程的“心脏”，负责：
  - 监听 I/O 事件（如网络连接、文件读写）。
  - 调度就绪的协程任务。
  - 处理回调和异常。
- Python 标准库 `asyncio` 提供默认事件循环，第三方库如 `uvloop` 可提升性能。

---

## **三、协程的实现**

### **1. 基本语法**
Python 3.5+ 使用 `async/await` 实现协程，以下是核心语法：

#### **定义协程函数**
```python
async def fetch_data():
    await asyncio.sleep(1)  # 模拟 I/O 操作
    return "Data"
```

#### **运行协程**
```python
import asyncio
async def main():
    result = await fetch_data()
    print(result)
asyncio.run(main())  # 输出：Data
```

#### **并发执行多个协程**
```python
import asyncio
async def task1(): await asyncio.sleep(1); print("Task 1")
async def task2(): await asyncio.sleep(1); print("Task 2")
async def main():
    await asyncio.gather(task1(), task2())  # 并发运行
asyncio.run(main())  # 输出：Task 1\nTask 2
```

### **2. 关键 API**
- **`asyncio.run(coro)`**：运行协程，创建事件循环（Python 3.7+）。
- **`asyncio.gather(*coros)`**：并发运行多个协程，等待全部完成。
- **`asyncio.create_task(coro)`**：创建任务，立即调度。
- **`await asyncio.sleep(n)`**：模拟异步延迟，暂停 n 秒。
- **`loop.run_until_complete(coro)`**：低级 API，运行协程至完成。

### **3. 第三方库支持**
- **`aiohttp`**：异步 HTTP 客户端/服务器。
  ```python
  import aiohttp
  async def fetch_url(url):
      async with aiohttp.ClientSession() as session:
          async with session.get(url) as resp:
              return await resp.text()
  ```
- **`aiomysql`**：异步 MySQL 客户端。
- **`uvloop`**：高性能事件循环，替换 `asyncio` 默认循环。
  ```python
  import uvloop
  asyncio.set_event_loop_policy(uvloop.EventLoopPolicy())
  ```

---

## **四、协程的优缺点**

### **1. 优点**
- **高并发**：单线程支持数万协程，适合 I/O 密集型任务。
- **低开销**：协程切换在用户态，内存和 CPU 消耗小。
- **简化异步逻辑**：`async/await` 语法清晰，替代回调地狱。
- **灵活性**：与事件循环结合，支持复杂异步流程。

### **2. 缺点**
- **不适合 CPU 密集型任务**：单线程无法利用多核，需结合 `multiprocessing`。
- **学习曲线**：异步编程需理解事件循环和协程调度。
- **调试复杂**：协程异常可能难以追踪，需工具支持。
- **生态限制**：部分库不支持异步，需异步替代品（如 `aiohttp` 替代 `requests`）。

---

## **五、测试相关性与实践**

协程在测试中常用于高并发场景（如 API 测试、爬虫）、性能优化和异步功能验证。以下是测试相关性和实践：

### **1. 功能测试**
- **目标**：验证协程逻辑正确性，如异步 API 调用。
- **工具**：`pytest-asyncio`。
- **示例**：
  ```python
  import asyncio
  import pytest
  @pytest.mark.asyncio
  async def test_fetch():
      async def fetch(): await asyncio.sleep(1); return "OK"
      assert await fetch() == "OK"
  ```
- **实践**：测试异步 Web 应用的路由处理。

### **2. 性能测试**
- **目标**：评估协程在高并发下的吞吐量和延迟。
- **工具**：`aiohttp`、`locust`。
- **示例**：
  ```python
  pip install locust
  ```
  ```python
  from locust import HttpUser, task
  import aiohttp
  class AsyncUser(HttpUser):
      @task
      async def fetch_task(self):
          async with aiohttp.ClientSession() as session:
              async with session.get("https://example.com") as session.get():
                  await resp.text()
  ```
- **实践**：用 Locust 测试 API 的异步性能，模拟 1000 用户。

### **3. 并发测试**
- **目标**：验证多协程协作的稳定性。
- **示例**：
  ```python
  import asyncio
  async def counter(id):
      for i in range(3):
          await asyncio.sleep(1)
          print(f"Task {id}: {i}")
  async def main():
      tasks = [asyncio.create_task(counter(i)) for i in range(3)]
      await asyncio.gather(*tasks)
  asyncio.run(main())
  ```
- **实践**：测试爬虫的并发请求，确保任务调度正确。

### **4. 异常处理测试**
- **工具**：`pytest`、`asyncio`。
- **示例**：**
  ```python
  import asyncio
  import pytest
  @pytest.mark.asyncio
  async def test_error():
      async def fetch():
          await asyncio.sleep(1)
          raise ValueError("Error")
      with pytest.raises(ValueError):
          await fetch()
  ```
- **实践**：测试异步数据库查询的异常处理。

### **5. 内存测试**
- **目标**：检查协程高并发下的内存泄漏。
- **工具**：`tracemalloc`。
- **示例**：**
  ```python
  import asyncio
  import tracemalloc
  tracemalloc.start()
  async def task():
      await asyncio.sleep(1)
  async def main():
      tasks = [asyncio.create_task(task()) for _ in range(1000)]
      await asyncio.gather(tasks)
  asyncio.run(main())
  snapshot = tracemalloc.take_snapshot()
  stats = snapshot.statistics('lineno')
  assert len(stats) < 10, "可能存在内存泄漏"
  ```
- **实践**：测试 Web 爬虫的内存稳定性。

### **6. 测试场景**
- **Web 应用**：测试 Flask/FastAPI 异步路由性能，用 `aiohttp` 模拟请求。
- **API 测试**：用 `pytest-asyncio` 测试异步 API，验证高并发响应。
- **爬虫**：测试 Scrapy 或自定义爬虫的协程效率。
- **自动化测试**：用协程加速 Selenium 测试多页面加载。

### **7. 常用工具**
- **pytest-asyncio**：支持异步测试。
  ```bash
  pip install pytest-asyncio
  ```
- **aiohttp**：异步 HTTP 请求。
- **locust**：异步性能测试。
- **tracemalloc**：内存分析。
- **uvloop**：高性能事件循环。

---

## **六、总结**

Python 协程是异步编程的核心，通过 `async/await` 和事件循环实现单线程高并发，特别适合 I/O 密集型任务。其原理基于协作式调度，核心组件包括协程对象、任务和事件循环。优点是轻量高效，缺点是不适合 CPU 密集型任务。在测试中，协程用于验证高并发性能、异步逻辑和内存管理，常见场景包括 API 测试、爬虫和 Web 应用。关键点：
- **定义**：轻量级用户态并发，`async/await` 实现。
- **机制**：事件循环驱动，协作式切换。
- **测试**：关注功能、性能、并发和内存。

通过合理使用协程和测试工具，可显著提升异步系统的性能和稳定性。

---

## **面试回答示例**

> **面试官**：Python 中什么是协程？请详细讲解。
>
> **回答**：协程是 Python 异步编程的轻量级并发机制，在单线程内通过协作式调度实现高并发，适合 I/O 密集任务。**原理**：用 `async def` 定义协程，`await` 暂停执行，事件循环（如 `asyncio`）调度任务。**实现**：通过 `asyncio.run`、`gather` 运行协程，支持 `aiohttp` 等异步库。**优点**：低开销、高并发；**缺点**：不适合 CPU 密集任务，调试较复杂。**测试中**，我用 `pytest-asyncio` 测试异步 API，用 `aiohttp` 模拟 1000 并发请求，优化后吞吐量提升 40%。需验证功能、性能和内存，用 `tracemalloc` 检测泄漏。场景包括爬虫、API 和 Web 测试。

---

## **面试加分点**
- **结构清晰**：分原理、实现、测试讲解。
- **技术深度**：提及事件循环、任务调度、I/O 多路复用。
- **测试实践**：结合性能、并发测试场景。
- **工具熟练度**：展示 `pytest-asyncio`、`aiohttp` 使用。
- **优化经验**：分享案例，如“提升 API 吞吐量”。

---

## **注意事项**
- **全面覆盖**：从定义到测试，结构化回答。
- **结合测试**：关联异步测试场景。
- **技术细节**：提供代码示例和工具。
- **面试准备**：熟悉协程 vs 线程/进程，准备相关问题（如事件循环原理）。


---


# TCP 拥塞是什么？‌

TCP 拥塞是指网络中数据包传输量超过网络处理能力，导致延迟增加、丢包或吞吐量下降的现象。TCP 通过拥塞控制机制（如慢启动、拥塞避免）动态调整发送速率以缓解拥塞，提高网络利用率，降低丢包率，改善用户体验。

**拥塞和流量控制不同：**

流量控制：发送方根据接收方的处理能力调整发送速度。

拥塞控制：发送方根据网络的承载能力调整发送速率。

### **精简要点**
- **原因**：网络带宽不足、路由器缓冲区溢出、突发流量。
- **影响**：延迟高、丢包、性能下降。
- **解决**：TCP 算法（慢启动、快重传、快恢复）优化流量。
- **测试相关**：模拟高负载网络，验证应用在拥塞下的稳定性。
  ```bash
  tc qdisc add dev eth0 root netem loss 5% delay 100ms
  ```
---

###  TCP 拥塞控制的四大算法

| 阶段                             | 描述                           |
| ------------------------------ | ---------------------------- |
| **慢启动（Slow Start）**            | 初始阶段，拥塞窗口从1开始指数增长，以快速探测可用带宽。 |
| **拥塞避免（Congestion Avoidance）** | 拥塞窗口线性增长，避免过快增长导致拥塞。         |
| **快速重传（Fast Retransmit）**      | 接收端收到重复 ACK 时，触发重传丢失的数据包。    |
| **快速恢复（Fast Recovery）**        | 重传后不回到慢启动，而是减小窗口并线性增长恢复速度。   |

---

### **面试回答示例**
> **面试官**：TCP 拥塞是什么？
>
> **回答**：TCP 拥塞是网络数据量超负荷，导致延迟、丢包的现象。TCP 用慢启动、拥塞避免等机制控制发送速率。在测试中，我用 `tc` 模拟网络拥塞，验证 API 在丢包下的响应，发现重试逻辑缺陷，优化后稳定性提升 20%。


---


# Linux中，如何查看日志？怎么查看后500条日志？‌

## **一、Linux 中如何查看日志**

### **1. 日志概述**
- **定义**：Linux 系统中，日志记录了系统、应用或服务的运行信息，通常存储在 `/var/log` 目录下，如 `/var/log/syslog` 系统日志、`/var/log/messages` 或应用自定义日志（如 `/var/log/nginx/error.log`）。
- **作用**：
  - 记录错误、警告、信息等事件。
  - 帮助诊断系统故障、性能问题或应用异常。
  - 提供测试验证的依据（如 API 请求状态）。
- **常见日志文件**：
  - 系统日志：`/var/log/syslog`（Ubuntu/Debian）、`/var/log/messages`（CentOS/RHEL）。
  - 服务日志：`/usr/log/nginx/access.log`（Nginx 访问日志）、`/var/log/nginx/error.log`（Nginx错误日志）。
  - 应用日志：如 `/var/log/app/app.log`（自定义应用日志）。
  - 权限日志：`/var/log/auth.log`（认证日志）。

### **2. 常用查看命令**

以下是 Linux 中查看日志的常用命令及其功能、特点和用法：

#### **2.1 `cat`**
- **功能**：一次性显示文件全部内容，适合小型日志文件。
- **语法**：
  ```bash
  cat [选项] 文件名
  ```
- **常用选项**：
  - `-n`：显示行号。
  - `-e`：显示控制字符（如 `$` 表示行末）。
- **示例**：
  ```bash
  $ cat /var/log/syslog
  # 显示 syslog 全部内容
  $ cat -n /var/log/nginx/access.log
  # 显示访问日志及行号
  ```
- **特点**：
  - 适合小文件，快速查看。
  - 不适合大文件，可能导致终端卡顿。
- **适用场景**：查看小型测试日志，快速检查内容格式。

#### **2.2 `less`**
- **功能**：分页显示，支持分页显示，支持交互式浏览，支持导航浏览，支持搜索浏览，适合大文件。
- **语法**：
  ```bash
  less [选项] 文件名
  ```
- **常用操作**：
  - `上下键`：上下移动。
  - `/pattern`：搜索模式（如 `/error`），按 `n` 查找下一个。
  - `q`：退出。
  - `g`/`G`：跳转到文件开头/或末尾。
- **示例**：
  ```bash
  $ less /var/log/messages
  # 分页查看 messages 日志
  $ less +F /var/log/app.log
  # 类似 tail -f，实时监控
  ```
- **特点**：
  - 内存占用低，适合大文件。
  - 支持搜索和实时监控。
- **适用场景**：分析大型日志，定位特定错误。

#### **2.3 `more`**
- **功能**：分页显示文件，但功能较 `less` 简单，逐步浏览。
- **语法**：
  ```bash
  more [选项] 文件名
  ```
- **常用操作**：
  - `空格`：下一页。
  - `回车`：下一行。
  - `q`：退出。
- **示例**：
  ```bash
  $ more /var/log/auth.log
  # 分页查看认证日志
  ```
- **特点**：
  - 比 `less` 简单，交互功能少。
  - 适合快速预览。
- **适用场景**：简单浏览中等大小的日志。

#### **2.4 `tail`**
- **功能**：显示文件末尾内容，适合查看最新日志，实时监控。
- **语法**：
  ```bash
  tail [选项] 文件名
  ```
- **常用选项**：
  - `-n <行数>`：显示末尾指定行数。
  - `-f`：实时监控文件变化（follow）。
  - `-F`：类似 `-f`，但支持文件轮替（如日志切割）。
- **示例**：
  ```bash
  $ tail /var/log/nginx/error.log
  # 显示错误日志末尾 10 行（默认）
  $ tail -f /var/log/app.log
  # 实时监控应用日志
  ```
- **特点**：
  - 高效查看最新日志。
  - 实时监控适合调试运行中系统。
- **适用场景**：监控服务日志，验证实时行为。

#### **2.5 `head`**
- **功能**：显示文件开头内容，与 `tail` 相对。
- **语法**：
  ```bash
  head [选项] 文件名
  ```
- **常用选项**：
  - `-n <行数>`：显示开头指定行数。
- **示例**：
  ```bash
  $ head -n 20 /var/log/syslog
  # 显示 syslog 前 20 行
  ```
- **特点**：
  - 适合查看日志元信息或早期记录。
- **适用场景**：检查日志文件头部的配置信息。

#### **2.6 `grep`**
- **功能**：过滤日志中匹配模式的行，常与上述命令结合。
- **语法**：
  ```bash
  grep [选项] 模式 文件名
  ```
- **常用选项**：
  - `-i`：忽略大小写。
  - `-n`：显示行号。
  - `-r`：递归搜索目录。
  - `-C <行数>`：显示匹配行前后指定行数。
- **示例**：
  ```bash
  $ grep "ERROR" /var/log/app.log
  # 查找包含 ERROR 的行
  $ grep -i -n "fail" /var/log/auth.log
  # 查找 fail（忽略大小写），显示行号
  ```
- **特点**：
  - 快速定位特定日志条目。
  - 支持正则表达式。
- **适用场景**：筛选错误或特定事件。

### **3. 其他工具**
- **journalctl**：查看 systemd 日志（现代 Linux 系统的日志管理工具）。
  ```bash
  $ journalctl -u nginx.service
  # 查看 Nginx 服务日志
  $ journalctl --since "2025-06-07"
  # 查看指定日期后的日志
  ```
- **dmesg**：查看内核环形缓冲区日志，适合硬件或驱动问题。
  ```bash
  $ dmesg | grep disk
  # 查看磁盘相关内核日志
  ```
- **vim**/**nano**：编辑器查看，适合小范围查看和修改。
  ```bash
  $ vim /var/log/syslog
  ```
- **awk**/**sed**：高级文本处理，提取特定字段。
  ```bash
  $ awk '/ERROR/ {print $1, $2}' app.log
  # 提取 ERROR 行的前两列
  ```

---

## **二、如何查看后 500 条日志？**

### **1. 核心命令：`tail -n 500`**
- **功能**：使用 `tail` 命令的 `-n` 选项，显示日志文件末尾 500 行。
- **语法**：
  ```bash
  tail -n 500 文件名
  ```
- **示例**：
  ```bash
  $ tail -n 500 /var/log/nginx/access.log
  # 显示 Nginx 访问日志最后 500 行
  $ tail -n 500 /var/log/app.log | less
  # 结合 less 分页查看
  ```
- **输出**：显示文件末尾 500 行内容，无文件名后缀。

### **2. 高级用法**
- **结合 `grep` 过滤**：
  ```bash
  $ tail -n 500 app.log | grep "ERROR"
  # 筛选最后 500 行中的错误
  ```
- **实时监控后 500 行**：
  ```bash
  $ tail -n 500 -f app.log
  # 显示后 500 行并继续监控
  ```
- **结合 `sort` 排序**：
  ```bash
  $ tail -n 500 app.log | sort -r
  # 按倒序显示后 500 行
  ```
- **结合 `wc` 统计**：
  ```bash
  $ tail -n 500 app.log | grep "FAIL" | wc -l
  # 统计后 500 行中 FAIL 的次数
  ```

### **3. 注意事项**
- **文件大小**：大文件使用 `tail` 高效，直接定位末尾。
- **行数不足**：若文件少于 500 行，显示全部内容。
- **权限问题**：确保有读取权限，否则需 `sudo`。
  ```bash
  sudo tail -n 500 /var/log/syslog
  ```
- **文件轮替**：日志可能被切割（如 `app.log.1`），需检查历史文件。
  ```bash
  tail -n 500 app.log app.log.1
  ```
- **编码问题**：非 UTF-8 日志可能乱码，用 `file` 检查编码。
  ```bash
  file app.log
  iconv -f GBK -t UTF-8 app.log | tail -n 500
  ```

---

## **三、测试相关性与实践**

查看日志是软件测试的核心技能，尤其在功能测试、性能测试和调试中。以下是 `tail -n 500` 和日志查看的测试应用：

### **1. 功能测试**
- **目标**：验证系统或应用行为是否符合预期。
- **示例**：
  ```bash
  tail -n 500 /var/log/nginx/access.log | grep " 200 "
  # 检查最近 500 次请求的成功状态码
  ```
- **实践**：测试 Web 应用登录功能，查看日志确认用户认证成功。

### **2. 性能测试**
- **目标**：分析高并发下日志生成速度和错误率。
- **示例**：
  ```bash
  tail -n 500 app.log | grep "timeout" | wc -l
  # 统计后 500 行中的超时错误
  ```
- **实践**：用 JMeter 测试 API，结合 `tail -f` 实时监控日志，发现性能瓶颈。

### **3. 错误定位**
- **目标**：快速定位异常或失败原因。
- **示例**：
  ```bash
  tail -n 500 /var/log/syslog | grep -i "error"
  # 查找系统日志中的错误
  ```
- **实践**：分析服务崩溃，定位到磁盘 I/O 错误，优化配置后恢复。

### **4. 自动化测试**
- **目标**：验证测试脚本的执行结果。
- **示例**：
  ```bash
  tail -n 500 test.log | grep "FAIL"
  # 检查自动化测试日志中的失败用例
  ```
- **实践**：运行 pytest 脚本，用 `tail` 提取失败日志，优化测试用例。

### **5. 安全测试**
- **目标**：检测异常访问或攻击行为。
- **示例**：
  ```bash
  tail -n 500 /var/log/auth.log | grep "failed"
  # 检查最近 500 行的登录失败记录
  ```
- **实践**：分析 SSH 暴力破解尝试，配置防火墙后减少攻击。

### **6. 实时监控**
- **目标**：调试运行中的系统。
- **示例**：
  ```bash
  tail -n 500 -f /var/log/nginx/error.log
  # 监控 Nginx 错误日志
  ```
- **实践**：上线新功能，实时观察日志，确保无异常。

### **7. 脚本集成**
- **目标**：自动化日志分析，生成报告。
- **示例**：
  ```bash
  #!/bin/bash
  error_count=$(tail -n 500 app.log | grep "ERROR" | wc -l)
  echo "Errors in last 500 lines: $error_count" >> report.txt
  ```
- **实践**：在 CI/CD 流水线中集成日志检查，触发告警。

---

## **四、常见问题与优化**

### **1. 常见问题**
- **权限不足**：需用 `sudo` 或切换用户。
  ```bash
  sudo tail -n 500 /var/log/secure
  ```
- **日志轮替**：当前日志可能不完整，需检查历史文件。
  ```bash
  ls -l /var/log/app.log*
  ```
- **大文件卡顿**：`cat` 处理大文件慢，用 `tail` 或 `less`。
- **乱码**：非 UTF-8 编码导致，需转换。
  ```bash
  iconv -f GBK -t UTF-8 app.log | less
  ```
- **行数不准**：末尾无换行符影响统计。
  ```bash
  cat -e app.log  # 检查隐藏字符
  ```

### **2. 优化技巧**
- **快速定位**：用 `grep` 结合 `tail` 缩小范围。
  ```bash
  tail -n 500 app.log | grep -C 2 "exception"
  ```
- **实时分析**：用 `watch` 动态统计。
  ```bash
  watch -n 1 'tail -n 500 app.log | grep "ERROR" | wc -l'
  ```
- **批量处理**：用 `find` 结合 `tail` 处理多文件。
  ```bash
  find /var/log -name "*.log" -exec tail -n 500 {} \;
  ```
- **压缩日志**：查看 `.gz` 压缩日志用 `zcat`。
  ```bash
  zcat app.log.gz | tail -n 500
  ```
- **结构化日志**：用 `jq` 解析 JSON 日志。
  ```bash
  tail -n 500 app.json.log | jq '.level | select(. == "error")'
  ```

---

## **五、总结**

Linux 中查看日志的常用命令包括 `cat`（全显示）、`less`（分页）、`tail`（末尾）、`more`（逐步）、`grep`（过滤）和 `journalctl`（systemd 日志）。要查看后 500 条日志，使用 `tail -n 500 文件名`，可结合 `grep`、`less` 等增强功能。其在测试中的应用包括功能验证、性能分析、错误定位和安全检测。关键点：
- **灵活高效**：`tail -n 500` 快速提取最新日志。
- **组合强大**：与 `grep`、`wc` 等结合，适配复杂场景。
- **测试核心**：日志分析是调试和验证的基础。

通过熟练使用这些命令和优化技巧，可快速定位问题，提升测试效率。

---

## **面试回答示例**

> **面试官**：Linux 中如何查看日志？怎么查看后 500 条日志？
>
> **回答**：Linux 查看日志常用 `cat` 显示全部，`less` 分页浏览，`tail` 查看末尾，`grep` 过滤模式，`journalctl` 查看 systemd 日志。**后 500 条**用 `tail -n 500 文件名`，如 `tail -n 500 /var/log/nginx/access.log`。可结合 `grep "ERROR"` 筛选错误或 `-f` 实时监控。**测试中**，我用 `tail -n 500` 分析 API 日志，发现 500 错误频发，用 `grep` 定位原因，优化后减少 30% 异常。需注意权限、轮替和编码问题，结合 `zcat` 处理压缩日志，`watch` 动态分析。

---

## **面试加分点**
- **结构清晰**：分命令和场景讲解。
- **技术深度**：提及选项、组合和优化。
- **测试实践**：结合错误定位、性能测试场景。
- **工具熟练度**：展示 `tail`、`grep`、`journalctl` 使用。
- **优化经验**：分享案例，如“减少 API 错误”。

---

## **注意事项**
- **全面覆盖**：包含多种命令和 `tail -n 500` 细节。
- **结合测试**：关联日志分析场景。
- **技术细节**：提供命令示例和优化。
- **面试准备**：熟悉日志相关命令，准备问题（如实时监控）。


---


# HR问，为什么要离职？？‌



---







📝 今日总结：
> 今天的视频1：selenium+WebDriver环境搭建(windows)